{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftrain = pd.read_csv('train_tokens_facts_number.csv', encoding = 'utf-8')\n",
    "dftest = pd.read_csv('test_tokens_facts_number.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wd = {}\n",
    "\n",
    "def word_tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [i.lower() for i in tokens if ( i not in string.punctuation+'—' )]\n",
    "    stop_words = stopwords.words('russian')\n",
    "    stop_words.extend(['что', 'это', 'так', 'вот', 'быть', 'как', 'в', '—', 'к', 'на'])\n",
    "    tokens = [i for i in tokens if ( i not in stop_words )]\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        if item in wd.keys():\n",
    "            stems.append(wd[item])\n",
    "        else:\n",
    "            w = SnowballStemmer(language='russian').stem(item)\n",
    "            wd[item] = w\n",
    "            stems.append(w)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0\n",
      "training epoch 1\n",
      "training epoch 2\n",
      "training epoch 3\n",
      "training epoch 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Какой ГОСТ предусматривает термин пиксель как единственно возможный для использования в области применения указанного стандарта?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = dftrain.tokens_question.tolist()\n",
    "paragraphs = dftrain.tokens_paragraph.tolist() + dftest.tokens_paragraph.tolist()\n",
    "texts = paragraphs + questions\n",
    "\n",
    "labels = []\n",
    "for label in dftrain['paragraph_id'].tolist():\n",
    "    labels.append('train_par_id_%s' % label)\n",
    "for label in dftest['paragraph_id'].tolist():\n",
    "    labels.append('test_par_id_%s' % label)\n",
    "for label in dftrain['question_id'].tolist():\n",
    "    labels.append('train_quest_id_%s' % label)\n",
    "\n",
    "class LabeledLineSentence(object):\n",
    "\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield doc2vec.LabeledSentence(words=word_tokenize(doc),\n",
    "                                         tags=[self.labels_list[idx]])\n",
    "\n",
    "sentences = LabeledLineSentence(texts, labels)\n",
    "it = sentences.__iter__()\n",
    "\n",
    "model = gensim.models.Doc2Vec(size=300, window=10, min_count=10, workers=12, alpha=0.03, min_alpha=0.025)\n",
    "model.build_vocab(it)\n",
    "\n",
    "for epoch in range(5):\n",
    "    print('training epoch %s'%epoch)\n",
    "    sentences = LabeledLineSentence(texts, labels)\n",
    "    it = sentences.__iter__()\n",
    "    model.train(it, total_examples=model.corpus_count, epochs=model.iter)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'saved_model.dat'\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec.load(fname)  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train_quest_id_26142', 0.4801800847053528),\n",
       " ('train_par_id_7141', 0.43672940135002136),\n",
       " ('train_quest_id_44246', 0.4327927529811859),\n",
       " ('train_quest_id_91308', 0.42102304100990295),\n",
       " ('train_quest_id_26759', 0.42047473788261414),\n",
       " ('train_quest_id_31677', 0.4202239215373993),\n",
       " ('train_quest_id_64345', 0.4155823886394501),\n",
       " ('train_quest_id_96648', 0.4148680567741394),\n",
       " ('train_quest_id_59875', 0.4145047664642334),\n",
       " ('train_quest_id_15207', 0.41430264711380005)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar('train_par_id_1436')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Относительно нормативности использовании термина в форме пиксел либо пиксель имеются различные мнения. Так Русский орфографический словарь РАН [4] квалифицирует форму пиксел как общеупотребительную, а форму пиксель как характерную разговорной профессиональной или разговорной и профессиональной речи (в сокращениях словаря нет расшифровки для разг. проф. речи, но есть отдельно разг. — разговорное, проф. — профессиональное[5]; однозначной расшифровки этого определения не даёт и справочная служба русского языка на портале Грамота.ру[6]). С другой стороны, действующий ГОСТ 27459-87[7] предусматривает термин пиксель как единственно возможный для использования в области применения указанного стандарта (компьютерная графика) и который является обязательным для применения в документации и литературе всех видов, входящих в сферу действия стандартизации или использующих результаты этой деятельности . При этом ГОСТ 27459-87 под термином пиксель понимает наименьший элемент поверхности визуализации, которому может быть независимым образом заданы цвет, интенсивность и другие характеристики изображения .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain[dftrain.paragraph_id==1436].paragraph.values[0]\n",
    "#['paragraph'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Какой термин пиксел или пиксель действующий ГОСТ 27459-87 предусматривает как единственно возможный для использования в области применения указанного стандарта?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain[dftrain.question_id==26142].question.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Какой термин пиксел или пиксель действующий ГОСТ 27459-87 предусматривает как единственно возможный для использования в области применения указанного стандарта?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain[dftrain.question_id==26142].question.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
